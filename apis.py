# -*- coding: utf-8 -*-
"""APIs.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1D7G7QaPkWdg_Agvb_muSy8Rkgv-3ys6_
"""

pip install google-api-python-client

from googleapiclient.discovery import build

api_key = 'AIzaSyDiuj1SC3OOVBsy4blYV_IEabj6GtwBvN8'
youtube = build('youtube', 'v3', developerKey=api_key)

video_id = 'aBltpsYTlGw'

# Call the commentThreads().list() method to retrieve comments
comments = youtube.commentThreads().list(
    part='snippet',
    videoId=video_id,
    textFormat='plainText'
).execute()

# Print the comments
for comment in comments['items']:
    print(comment['snippet']['topLevelComment']['snippet']['textDisplay'])

from googleapiclient.discovery import build
from datetime import datetime

api_key = 'AIzaSyDiuj1SC3OOVBsy4blYV_IEabj6GtwBvN8'
youtube = build('youtube', 'v3', developerKey=api_key)

# Set the video ID
video_id = 'aBltpsYTlGw'

# Set the maximum number of comments to retrieve per page
max_results = 100

# Set the initial page token
page_token = None

comments = []

while True:
    # Call the commentThreads().list() method to retrieve comments
    response = youtube.commentThreads().list(
        part='snippet',
        videoId=video_id,
        textFormat='plainText',
        maxResults=max_results,
        pageToken=page_token
    ).execute()

    # Add the comments to the list
    for item in response['items']:
        comment = item['snippet']['topLevelComment']['snippet']['textDisplay']
        comments.append(comment)

    # Check if there are more comments
    if 'nextPageToken' in response:
        page_token = response['nextPageToken']
    else:
        break

# Print the comments
for comment in comments:
    print(comment)

import csv
from googleapiclient.discovery import build

api_key = 'AIzaSyDiuj1SC3OOVBsy4blYV_IEabj6GtwBvN8'
youtube = build('youtube', 'v3', developerKey=api_key)

# Set the video ID
video_id = 'aBltpsYTlGw'

# Set the maximum number of comments to retrieve per page
max_results = 100

# Set the initial page token
page_token = None

comments = []

while True:
    # Call the commentThreads().list() method to retrieve comments
    response = youtube.commentThreads().list(
        part='snippet',
        videoId=video_id,
        textFormat='plainText',
        maxResults=max_results,
        pageToken=page_token
    ).execute()

    # Add the comments to the list
    for item in response['items']:
        comment = item['snippet']['topLevelComment']['snippet']['textDisplay']
        comments.append(comment)

    # Check if there are more comments
    if 'nextPageToken' in response:
        page_token = response['nextPageToken']
    else:
        break

# Write the comments to a CSV file
with open('comments.csv', 'w', newline='', encoding='utf-8') as file:
    writer = csv.writer(file)
    writer.writerow(['Comment'])

    for comment in comments:
        writer.writerow([comment])